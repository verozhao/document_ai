# Cloud Workflow for Document AI Automated Training with Proper Labeling
# This version correctly formats training data with labels

main:
  params: [input]
  steps:
    - init:
        assign:
          - project_id: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
          - processor_id: ${input.processor_id}
          - training_type: ${input.training_type}
          - location: ${default(input.location, "us")}
          - bucket_name: ${default(input.bucket_name, "document-ai-test-veronica")}
          - processor_path: ${"projects/" + project_id + "/locations/" + location + "/processors/" + processor_id}
          - batch_id: ${"batch_" + text.substring(sys.get_env("GOOGLE_CLOUD_WORKFLOW_EXECUTION_ID"), 0, 12)}
          - start_time: ${sys.now()}

    - log_start:
        call: sys.log
        args:
          text: '${"Starting " + training_type + " training for processor " + processor_id}'
          severity: "INFO"

    - create_training_batch:
        call: http.post
        args:
          url: ${"https://firestore.googleapis.com/v1/projects/" + project_id + "/databases/(default)/documents/training_batches"}
          auth:
            type: OAuth2
          body:
            fields:
              batch_id: 
                stringValue: ${batch_id}
              processor_id:
                stringValue: ${processor_id}
              training_type:
                stringValue: ${training_type}
              status:
                stringValue: "preparing"
              started_at:
                timestampValue: ${time.format(sys.now())}

    - get_training_documents:
        try:
          steps:
            - query_documents:
                call: http.post
                args:
                  url: ${"https://firestore.googleapis.com/v1/projects/" + project_id + "/databases/(default)/documents:runQuery"}
                  auth:
                    type: OAuth2
                  body:
                    structuredQuery:
                      from:
                        - collectionId: "processed_documents"
                      where:
                        compositeFilter:
                          op: "AND"
                          filters:
                            - fieldFilter:
                                field:
                                  fieldPath: "processor_id"
                                op: "EQUAL"
                                value:
                                  stringValue: ${processor_id}
                            - fieldFilter:
                                field:
                                  fieldPath: "status"
                                op: "EQUAL"
                                value:
                                  stringValue: ${if(training_type == "initial", "pending_initial_training", "completed")}
                            - fieldFilter:
                                field:
                                  fieldPath: "used_for_training"
                                op: "EQUAL"
                                value:
                                  booleanValue: false
                            - fieldFilter:
                                field:
                                  fieldPath: "document_label"
                                op: "NOT_EQUAL"
                                value:
                                  nullValue: {}
                      limit: 100
                result: query_result

            - process_documents:
                assign:
                  - training_documents: []
                  - label_counts: {}
                  - dataset_documents: []

            - extract_documents:
                for:
                  value: doc
                  in: ${query_result}
                  steps:
                    - get_doc_fields:
                        assign:
                          - doc_id: ${doc.document.fields.document_id.stringValue}
                          - gcs_uri: ${doc.document.fields.gcs_uri.stringValue}
                          - doc_label: ${doc.document.fields.document_label.stringValue}
                          
                    - create_training_doc:
                        assign:
                          - training_doc:
                              documentId: ${doc_id}
                              gcsUri: ${gcs_uri}
                              label: ${doc_label}
                              
                    - add_to_list:
                        assign:
                          - training_documents: ${list.concat(training_documents, [training_doc])}
                          
                    - count_labels:
                        assign:
                          - label_counts[doc_label]: ${default(map.get(label_counts, doc_label), 0) + 1}

        except:
          as: e
          steps:
            - log_error:
                call: sys.log
                args:
                  text: '${"Error getting training documents: " + json.encode_to_string(e)}'
                  severity: "ERROR"
            - fail_workflow:
                raise: ${e}

    - check_document_count:
        switch:
          - condition: ${len(training_documents) == 0}
            steps:
              - log_no_documents:
                  call: sys.log
                  args:
                    text: "No labeled documents found for training"
                    severity: "WARNING"
              - cancel_batch:
                  return: "No documents for training"

    - log_training_info:
        call: sys.log
        args:
          text: '${"Found " + string(len(training_documents)) + " documents with labels: " + json.encode_to_string(label_counts)}'
          severity: "INFO"

    - prepare_training_dataset:
        try:
          steps:
            - create_dataset_prefix:
                assign:
                  - dataset_prefix: ${"gs://" + bucket_name + "/training-datasets/" + batch_id + "/"}
                  
            - create_import_config:
                assign:
                  - import_configs: []
                  
            - build_import_configs:
                for:
                  value: doc
                  in: ${training_documents}
                  steps:
                    - create_config:
                        assign:
                          - import_config:
                              gcsSource:
                                inputUris: [${doc.gcsUri}]
                              documentType: ${doc.label}
                              
                    - add_config:
                        assign:
                          - import_configs: ${list.concat(import_configs, [import_config])}

            - start_training:
                call: http.post
                args:
                  url: ${"https://" + location + "-documentai.googleapis.com/v1/" + processor_path + "/processorVersions:train"}
                  auth:
                    type: OAuth2
                  body:
                    processorVersion:
                      displayName: ${"auto-train-" + text.substring(batch_id, 6, 12) + "-" + time.format(sys.now(), "%Y%m%d")}
                    documentSchema:
                      description: "Auto-generated schema for document classification"
                      displayName: "Document Classification Schema"
                      entityTypes: ${build_entity_types(label_counts)}
                    inputData:
                      trainingDocuments:
                        gcsDocuments:
                          documents: ${build_gcs_documents(training_documents)}
                result: training_operation

            - update_batch_status:
                call: http.patch
                args:
                  url: ${"https://firestore.googleapis.com/v1/projects/" + project_id + "/databases/(default)/documents/training_batches/" + batch_id}
                  auth:
                    type: OAuth2
                  body:
                    fields:
                      status:
                        stringValue: "training"
                      training_operation_id:
                        stringValue: ${training_operation.name}
                      document_count:
                        integerValue: ${len(training_documents)}
                      label_counts:
                        mapValue:
                          fields: ${convert_counts_to_firestore(label_counts)}
                  query:
                    updateMask: "status,training_operation_id,document_count,label_counts"

        except:
          as: e
          steps:
            - log_training_error:
                call: sys.log
                args:
                  text: '${"Error starting training: " + json.encode_to_string(e)}'
                  severity: "ERROR"
            - update_failed:
                call: http.patch
                args:
                  url: ${"https://firestore.googleapis.com/v1/projects/" + project_id + "/databases/(default)/documents/training_batches/" + batch_id}
                  auth:
                    type: OAuth2
                  body:
                    fields:
                      status:
                        stringValue: "failed"
                      error_message:
                        stringValue: ${json.encode_to_string(e)}
                  query:
                    updateMask: "status,error_message"
            - raise_error:
                raise: ${e}

    - monitor_training:
        call: monitor_training_operation
        args:
          operation_name: ${training_operation.name}
          location: ${location}
        result: training_result

    - check_training_success:
        switch:
          - condition: ${training_result.done == true and training_result.error == null}
            next: deploy_model
          - condition: ${training_result.error != null}
            steps:
              - log_failure:
                  call: sys.log
                  args:
                    text: '${"Training failed: " + json.encode_to_string(training_result.error)}'
                    severity: "ERROR"
              - mark_failed:
                  return: "Training failed"

    - deploy_model:
        try:
          steps:
            - extract_version:
                assign:
                  - version_name: ${training_result.response.name}
                  
            - start_deployment:
                call: http.post
                args:
                  url: ${"https://" + location + "-documentai.googleapis.com/v1/" + version_name + ":deploy"}
                  auth:
                    type: OAuth2
                result: deploy_operation
                
            - monitor_deployment:
                call: monitor_deployment_operation
                args:
                  operation_name: ${deploy_operation.name}
                  location: ${location}
                result: deploy_result
                
            - set_default_version:
                switch:
                  - condition: ${deploy_result.done == true and deploy_result.error == null}
                    steps:
                      - update_processor:
                          call: http.patch
                          args:
                            url: ${"https://" + location + "-documentai.googleapis.com/v1/" + processor_path}
                            auth:
                              type: OAuth2
                            body:
                              defaultProcessorVersion: ${version_name}
                            query:
                              updateMask: "defaultProcessorVersion"

        except:
          as: e
          steps:
            - log_deploy_error:
                call: sys.log
                args:
                  text: '${"Deployment error: " + json.encode_to_string(e)}'
                  severity: "ERROR"

    - mark_documents_used:
        parallel:
          for:
            value: doc
            in: ${training_documents}
            steps:
              - update_doc:
                  call: http.patch
                  args:
                    url: ${"https://firestore.googleapis.com/v1/projects/" + project_id + "/databases/(default)/documents/processed_documents/" + doc.documentId}
                    auth:
                      type: OAuth2
                    body:
                      fields:
                        used_for_training:
                          booleanValue: true
                        training_batch_id:
                          stringValue: ${batch_id}
                    query:
                      updateMask: "used_for_training,training_batch_id"

    - finalize:
        call: http.patch
        args:
          url: ${"https://firestore.googleapis.com/v1/projects/" + project_id + "/databases/(default)/documents/training_batches/" + batch_id}
          auth:
            type: OAuth2
          body:
            fields:
              status:
                stringValue: "deployed"
              completed_at:
                timestampValue: ${time.format(sys.now())}
          query:
            updateMask: "status,completed_at"

    - return_success:
        return:
          batch_id: ${batch_id}
          status: "success"
          documents_trained: ${len(training_documents)}
          label_distribution: ${label_counts}

# Helper subworkflows

build_entity_types:
  params: [label_counts]
  steps:
    - create_entities:
        assign:
          - entity_types: []
    - build_types:
        for:
          value: label
          in: ${keys(label_counts)}
          steps:
            - create_type:
                assign:
                  - entity_type:
                      type: ${label}
                      displayName: ${text.replace_all(text.replace_all(label, "_", " "), "-", " ")}
                      baseTypes: ["document"]
            - add_type:
                assign:
                  - entity_types: ${list.concat(entity_types, [entity_type])}
    - return_types:
        return: ${entity_types}

build_gcs_documents:
  params: [training_documents]
  steps:
    - create_list:
        assign:
          - gcs_docs: []
    - build_docs:
        for:
          value: doc
          in: ${training_documents}
          steps:
            - create_doc:
                assign:
                  - gcs_doc:
                      gcsUri: ${doc.gcsUri}
                      mimeType: "application/pdf"
            - add_doc:
                assign:
                  - gcs_docs: ${list.concat(gcs_docs, [gcs_doc])}
    - return_docs:
        return: ${gcs_docs}

convert_counts_to_firestore:
  params: [counts]
  steps:
    - convert:
        assign:
          - firestore_map: {}
    - build_map:
        for:
          value: label
          in: ${keys(counts)}
          steps:
            - add_field:
                assign:
                  - firestore_map[label]:
                      integerValue: ${counts[label]}
    - return_map:
        return: ${firestore_map}

monitor_training_operation:
  params: [operation_name, location]
  steps:
    - poll_loop:
        steps:
          - get_operation:
              call: http.get
              args:
                url: ${"https://" + location + "-documentai.googleapis.com/v1/" + operation_name}
                auth:
                  type: OAuth2
              result: op_status
          - check_done:
              switch:
                - condition: ${op_status.done == true}
                  return: ${op_status}
          - wait:
              call: sys.sleep
              args:
                seconds: 30
          - continue:
              next: poll_loop

monitor_deployment_operation:
  params: [operation_name, location]
  steps:
    - poll_loop:
        steps:
          - get_operation:
              call: http.get
              args:
                url: ${"https://" + location + "-documentai.googleapis.com/v1/" + operation_name}
                auth:
                  type: OAuth2
              result: op_status
          - check_done:
              switch:
                - condition: ${op_status.done == true}
                  return: ${op_status}
          - wait:
              call: sys.sleep
              args:
                seconds: 30
          - continue:
              next: poll_loop